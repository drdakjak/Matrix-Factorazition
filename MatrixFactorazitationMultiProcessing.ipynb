{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Process, Pool\n",
    "from threading import Thread\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nacteni dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"/home/kuba/ownCloud/ModGen-fac-mat/sample-data-v2/movielens_1m/items.json\",'r') as f:\n",
    "    items = json.loads(f.read())\n",
    "\n",
    "with open(\"/home/kuba/ownCloud/ModGen-fac-mat/sample-data-v2/movielens_1m/properties.json\",'r') as f:\n",
    "    properties = json.loads(f.read())\n",
    "    \n",
    "with open(\"/home/kuba/ownCloud/ModGen-fac-mat/sample-data-v2/movielens_1m/user.folds.json\",'r') as f:\n",
    "    user_folds = json.loads(f.read())\n",
    "    \n",
    "with open(\"/home/kuba/ownCloud/ModGen-fac-mat/sample-data-v2/movielens_1m/users.int2str.json\",'r') as f:\n",
    "    users_int2str = json.loads(f.read())\n",
    "    \n",
    "with open(\"/home/kuba/ownCloud/ModGen-fac-mat/sample-data-v2/movielens_1m/users.str2int.json\",'r') as f:\n",
    "    users_str2int = json.loads(f.read())\n",
    "      \n",
    "ratings = pd.read_csv('/home/kuba/ownCloud/ModGen-fac-mat/sample-data-v2/movielens_1m/ratings.csv')\n",
    "\n",
    "with open(\"/home/kuba/ownCloud/ModGen-fac-mat/sample-data-v2/movielens_1m/items.int2str.json\",'r') as f:\n",
    "    items_int2str = json.loads(f.read())\n",
    "    \n",
    "with open(\"/home/kuba/ownCloud/ModGen-fac-mat/sample-data-v2/movielens_1m/items.str2int.json\",'r') as f:\n",
    "    items_str2int = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faktorizace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import ctypes\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# %load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MatrixFactorization:\n",
    "    def __init__(self, ratings, no_factors):\n",
    "        self.Ratings = ratings.pivot_table(columns=['itemId'],index=['userId'],values='rating')\n",
    "        self.Ratings_matrix = self.Ratings.values\n",
    "        self.Weights = np.isfinite(self.Ratings_matrix).astype(np.float64, copy=False)\n",
    "        self.Idx = np.isfinite(self.Ratings_matrix)\n",
    "        self.ratings_dict = dict(ratings.apply(lambda r:( (str(int(r.userId)),str(int(r.itemId))),{\n",
    "                                                                    'rating':r.rating,\n",
    "                                                                     }), axis=1).values)\n",
    "        self.no_factors = no_factors\n",
    "        \n",
    "        shared_array_base = multiprocessing.Array(ctypes.c_double, np.random.rand(self.Ratings.shape[0]* no_factors))\n",
    "        shared_array = np.ctypeslib.as_array(shared_array_base.get_obj())\n",
    "        shared_array = shared_array.reshape(self.Ratings.shape[0], no_factors)\n",
    "        self.Users = shared_array.reshape(self.Ratings.shape[0], no_factors)\n",
    "        \n",
    "        shared_array_base = multiprocessing.Array(ctypes.c_double, np.random.rand(self.Ratings.shape[1]* no_factors))\n",
    "        shared_array = np.ctypeslib.as_array(shared_array_base.get_obj())\n",
    "        shared_array = shared_array.reshape(no_factors, self.Ratings.shape[1])\n",
    "        self.Items = shared_array.reshape(no_factors, self.Ratings.shape[1])\n",
    "        \n",
    "    '''\n",
    "    RMSE\n",
    "    '''  \n",
    "    def get_error(self, R, U, V, W):\n",
    "        return np.sum(np.nan_to_num((W * (R - np.dot(U, V))))**2)\n",
    "    \n",
    "    '''\n",
    "    OPTIMAZE\n",
    "    '''\n",
    "     \n",
    "    def optimize_rmse_solver(self, lambda_, no_iterations):\n",
    "        weighted_errors = []\n",
    "        R = np.nan_to_num(self.Ratings_matrix)\n",
    "        V = self.Items\n",
    "        U = self.Users\n",
    "        W = self.Idx.astype(np.float64, copy=False)\n",
    "        \n",
    "        for ii in range(no_iterations):\n",
    "            for u, Wu in enumerate(W):\n",
    "                U[u] = np.linalg.solve(np.dot(V, np.dot(np.diag(Wu), V.T)) + lambda_ * np.eye(self.no_factors),\n",
    "                                       np.dot(V, np.dot(np.diag(Wu), R[u].T))).T\n",
    "            for i, Wi in enumerate(W.T):\n",
    "                V[:,i] = np.linalg.solve(np.dot(U.T, np.dot(np.diag(Wi), U)) + lambda_ * np.eye(self.no_factors),\n",
    "                                         np.dot(U.T, np.dot(np.diag(Wi), R[:, i])))\n",
    "            weighted_errors.append(self.get_error(R, U, V, W))\n",
    "            if(not ii % 20):\n",
    "                print('{}th iteration is completed'.format(ii))\n",
    "                print(weighted_errors[-1])\n",
    "                self.R_hat = np.dot(U,V)\n",
    "                \n",
    "        return weighted_errors\n",
    "    \n",
    "    def compute_item_factor(self, batch):\n",
    "        R, V, U, Idx, lambda_, alfa = self.Ratings_matrix, self.Items, self.Users, self.Idx, self.lambda_, self.alfa\n",
    "        for i in batch:\n",
    "            V[:,i] += -alfa * (np.dot((np.dot(V[:,i],U[Idx[:,i],:].T) - R[Idx[:,i],i]), U[Idx[:,i],:]) + lambda_ * V[:,i])\n",
    "        return\n",
    "    \n",
    "    def compute_user_factor(self, batch):\n",
    "        R, V, U, Idx, lambda_, alfa = self.Ratings_matrix, self.Items, self.Users, self.Idx, self.lambda_, self.alfa\n",
    "        for u in batch:\n",
    "            self.Users[u] += -alfa * (np.dot((np.dot(U[u], V[:,Idx[u,:]]) - R[u, Idx[u,:]]), V[:,Idx[u,:]].T) + lambda_* U[u] )\n",
    "        return\n",
    "    \n",
    "    def optimize_rmse_gradient_descent(self, lambda_, no_iterations, alfa = 0.01, no_process = 1):\n",
    "        weighted_errors = []\n",
    "        R = np.nan_to_num(self.Ratings_matrix)\n",
    "        V = self.Items\n",
    "        U = self.Users\n",
    "        Idx = self.Idx\n",
    "        self.lambda_ = lambda_\n",
    "        self.alfa = alfa\n",
    "        tV = self.Items.copy()\n",
    "        \n",
    "        print(\"ID Items: \", id(self.Items))\n",
    "        \n",
    "        \n",
    "        step_item = int(np.ceil(len(V.T)/float(no_process)))\n",
    "        step_user = int(np.ceil(len(U)/float(no_process)))\n",
    "        \n",
    "        item_range = [range(i,min(len(V.T), i+step_item)) for i in range(0, len(V.T), step_item)]\n",
    "        user_range = [range(i,min(len(U), i+step_user)) for i in range(0, len(U), step_user)]\n",
    "        print(\"Item range\", item_range)\n",
    "        print(\"User range\", user_range)\n",
    "        \n",
    "        for ii in range(no_iterations):\n",
    "            #ITEMS\n",
    "            process = []\n",
    "            for batch in item_range:\n",
    "                p = Process(target = self.compute_item_factor, args = (batch, ))\n",
    "                process.append(p)\n",
    "                p.daemon = True\n",
    "                p.start()\n",
    "            \n",
    "            [p.join() for p in process]\n",
    "            \n",
    "            #USERS\n",
    "            process = []\n",
    "            for batch in user_range:\n",
    "                p = Process(target = self.compute_user_factor, args = (batch, ))\n",
    "                process.append(p)\n",
    "                p.daemon = True\n",
    "                p.start()\n",
    "            \n",
    "            [p.join() for p in process]\n",
    "\n",
    "            weighted_errors.append(self.get_error(self.Ratings_matrix, self.Users, self.Items, self.Idx))\n",
    "            if(not ii % 200):\n",
    "                print('{}th iteration is completed'.format(ii))\n",
    "                print(weighted_errors[-1])\n",
    "                \n",
    "                self.R_hat = np.dot(U,V)\n",
    "                \n",
    "        return weighted_errors\n",
    "    \n",
    "    def plot_rmse(self, weighted_errors):\n",
    "        plt.plot(np.log(weighted_errors), label=\"weighted error: \"+str(weighted_errors[-1]))\n",
    "        plt.ylabel(\"RMSE log scale\")\n",
    "        plt.xlabel(\"no iterations\")\n",
    "\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def optimaze(self, lambda_, no_iterations, loss_function=\"RMSE\", method=\"solver\", alfa=0.001, no_process = 1):\n",
    "        if(loss_function == \"RMSE\" and method == \"solver\"):\n",
    "            weighted_errors = self.optimize_rmse_solver(lambda_, no_iterations)\n",
    "            \n",
    "        if(loss_function == \"RMSE\" and method == \"gradient-descent\"):\n",
    "            weighted_errors = self.optimize_rmse_gradient_descent(lambda_, no_iterations, alfa, no_process)\n",
    "\n",
    "        self.plot_rmse(weighted_errors)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MFact = MatrixFactorization(ratings[:400000].copy(), 30)\n",
    "# %time MFact.optimaze(0.001, 200, method=\"gradient-descent\", alfa = 0.0001, no_process = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %lprun -f MFact.rmse_optimalization MFact.rmse_optimalization(0.001, 0.0001, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID Items:  140399222685488\n",
      "Item range [range(0, 618), range(618, 1236), range(1236, 1854), range(1854, 2472), range(2472, 3090), range(3090, 3706)]\n",
      "User range [range(0, 1007), range(1007, 2014), range(2014, 3021), range(3021, 4028), range(4028, 5035), range(5035, 6040)]\n",
      "CPU times: user 548 ms, sys: 13.9 s, total: 14.4 s\n",
      "Wall time: 25.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(0, 58, 111026)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "\n",
    "MFact = MatrixFactorization(ratings[:4000000].copy(), 30)\n",
    "%time MFact.optimaze(0.001, 50, method=\"gradient-descent\", alfa = 0.0001, no_process = 6)\n",
    "\n",
    "datetime.datetime.now() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
