{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from multiprocessing import Process, Pool\n",
    "from threading import Thread\n",
    "import time\n",
    "import timeit\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nacteni dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = \"movielens_1m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"/home/kuba/ownCloud/ModGen-fac-mat/sample-data-v2/\"+dataset+\"/items.json\",'r') as f:\n",
    "    items = json.loads(f.read())\n",
    "\n",
    "with open(\"/home/kuba/ownCloud/ModGen-fac-mat/sample-data-v2/\"+dataset+\"/properties.json\",'r') as f:\n",
    "    properties = json.loads(f.read())\n",
    "    \n",
    "with open(\"/home/kuba/ownCloud/ModGen-fac-mat/sample-data-v2/\"+dataset+\"/user.folds.json\",'r') as f:\n",
    "    user_folds = json.loads(f.read())\n",
    "    \n",
    "with open(\"/home/kuba/ownCloud/ModGen-fac-mat/sample-data-v2/\"+dataset+\"/users.int2str.json\",'r') as f:\n",
    "    users_int2str = json.loads(f.read())\n",
    "    \n",
    "with open(\"/home/kuba/ownCloud/ModGen-fac-mat/sample-data-v2/\"+dataset+\"/users.str2int.json\",'r') as f:\n",
    "    users_str2int = json.loads(f.read())\n",
    "      \n",
    "ratings = pd.read_csv(\"/home/kuba/ownCloud/ModGen-fac-mat/sample-data-v2/\"+dataset+\"/ratings.csv\",dtype = {'rating': np.float, 'itemId': np.str, 'userId':np.str} )\n",
    "\n",
    "with open(\"/home/kuba/ownCloud/ModGen-fac-mat/sample-data-v2/\"+dataset+\"/items.int2str.json\",'r') as f:\n",
    "    items_int2str = json.loads(f.read())\n",
    "    \n",
    "with open(\"/home/kuba/ownCloud/ModGen-fac-mat/sample-data-v2/\"+dataset+\"/items.str2int.json\",'r') as f:\n",
    "    items_str2int = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faktorizace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import ctypes\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import scipy.sparse.linalg as sparse_lg\n",
    "import datetime\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "# %load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MatrixFactorization:\n",
    "    def __init__(self, ratings, no_factors, relevant = .25, testset_amount = 0.2):\n",
    "        self.Dataset = ratings\n",
    "        self.Ratings = ratings.pivot_table(columns=['userId'],index=['itemId'],values='rating')\n",
    "        self.Ratings_matrix = self.Ratings.values\n",
    "        \n",
    "        self.Testset = self.init_testset(testset_amount, relevant)\n",
    "        \n",
    "        self.Idx = np.isfinite(self.Ratings_matrix)\n",
    "        self.Weights = np.isfinite(self.Ratings_matrix).astype(np.float64, copy=False)\n",
    "\n",
    "        self.Ratings_matrix = np.nan_to_num(self.Ratings_matrix)\n",
    "        self.Ratings_matrix_sparse = sp.csr_matrix(self.Ratings_matrix)\n",
    "#         self.ratings_dict = dict(ratings.apply(lambda r:( (str(int(r.userId)),str(int(r.itemId))),{\n",
    "#                                                                     'rating':r.rating,\n",
    "#                                                                      }), axis=1).values)\n",
    "        self.relevant = relevant\n",
    "        self.number_of_obs_relevant_items = dict([(i,1+np.sum(self.Ratings_matrix[i,:] >= relevant)) for i in range(self.Ratings_matrix.shape[0]) ])\n",
    "\n",
    "        self.testset_amount = testset_amount\n",
    "        self.no_factors = no_factors\n",
    "        self.Users = None\n",
    "        self.Items = None\n",
    "      \n",
    "    def init(self):\n",
    "        if(self.random_init): \n",
    "            user_shared_array_base = multiprocessing.Array(ctypes.c_double, np.random.rand(self.Ratings.shape[1]* self.no_factors), lock=False)\n",
    "            user_shared_array = np.frombuffer(user_shared_array_base,dtype=float)    \n",
    "            self.Users = user_shared_array.reshape(self.Ratings.shape[1], self.no_factors)\n",
    "            \n",
    "            \n",
    "            item_shared_array_base = multiprocessing.Array(ctypes.c_double, np.random.rand(self.Ratings.shape[0] * self.no_factors), lock= False)\n",
    "            item_shared_array = np.frombuffer(item_shared_array_base,dtype=float)\n",
    "            self.Items = item_shared_array.reshape(self.Ratings.shape[0], self.no_factors)\n",
    "            \n",
    "    def init_optimizer(self):\n",
    "        if(self.weights_mode == \"AllRank\"):\n",
    "            self.Weights[self.Idx==False] = self.weight\n",
    "            self.Weights_sparse = sp.csr_matrix(self.Weights)\n",
    "            print(\"** Set weight: \",self.weight, \" to missing ratings **\")\n",
    "\n",
    "        elif(self.weights_mode == \"AllRank-pop\"):\n",
    "            pass\n",
    "        \n",
    "        elif(self.weights_mode == \"MF-RMSE\"):\n",
    "            assert self.weight == 0, \"Weight of missiong values MF-RMSE mode must be 0!\"\n",
    "            self.Weights_sparse = sp.csr_matrix(self.Weights)\n",
    "            \n",
    "        if(self.imputation_value != 0 ):   \n",
    "            self.Ratings_matrix[self.Idx==False] = self.imputation_value\n",
    "            self.Ratings_matrix_sparse = sp.csr_matrix(self.Ratings_matrix)\n",
    "            print(\"** Surrogate missing rating values by imputation value: \", self.imputation_value, \" **\")\n",
    "            \n",
    "        \n",
    "    def init_testset(self, testset_amount, relevant):\n",
    "        ratings = self.Ratings_matrix\n",
    "        Testset = {}\n",
    "        \n",
    "        for i_user in range(ratings.shape[1]):\n",
    "            idx = np.where(ratings[:,i_user] >= relevant)[0]\n",
    "            if(testset_amount):\n",
    "                if(len(idx)):\n",
    "                    random_choice = np.random.choice( idx, size = int(np.ceil(len(idx)*testset_amount)), replace = False)            \n",
    "                    Testset[i_user] = {\"indices\": random_choice, \"ratings\": ratings[random_choice,i_user]}\n",
    "                    ratings[random_choice,i_user] = np.nan\n",
    "            else:\n",
    "                Testset[i_user] = {\"indices\": idx, \"ratings\": ratings[idx,i_user]}\n",
    "                \n",
    "        return Testset\n",
    "    '''\n",
    "    ATOP\n",
    "    '''\n",
    "    \n",
    "    def NRANKs_u(self, user, items):\n",
    "        prediction = self.R_hat[:,user]\n",
    "        ranks = np.argsort(prediction)\n",
    "        N = len(prediction)\n",
    "        nranks = np.array([np.where(ranks==item)[0][0] for item in items])/N\n",
    "        return nranks\n",
    "\n",
    "   \n",
    "    \n",
    "    def ATOP(self):\n",
    "        atop = []\n",
    "        RMSE = []\n",
    "        for user, cont_id_rat in self.Testset.items():\n",
    "            RMSE.extend(self.R_hat[cont_id_rat['indices'], user] - cont_id_rat['ratings'])\n",
    "            nranks = self.NRANKs_u(user, cont_id_rat['indices'])\n",
    "            atop.extend(nranks)\n",
    "        \n",
    "        return np.mean(atop), sqrt(np.mean((np.array(RMSE)**2)))\n",
    "            \n",
    "    \n",
    "    def RECALL_u(self, u, K, beta):\n",
    "        prediction = self.R_hat[:,u]\n",
    "        T = self.Test_matrix\n",
    "        idx = np.argsort(prediction)[::-1][:K]\n",
    "        idx_relevant = np.where(T[:,u] == True)\n",
    "    \n",
    "        return np.sum(T[idx,u])/np.sum(T[:,u]), np.sum([1/(self.number_of_obs_relevant_items[i]**beta) for i in idx_relevant[0]]) #TODO IndexError: index 7591 is out of bounds for axis 0 with size 717\n",
    "\n",
    "\n",
    "    \n",
    "    def RECALL(self, K, beta):\n",
    "        recall = 0\n",
    "        for u in range(len(self.Users)):\n",
    "            r, w = self.RECALL_u(u, K, beta)\n",
    "            recall += r*w\n",
    "        return recall\n",
    "             \n",
    "        \n",
    "    '''\n",
    "    RMSE\n",
    "    '''  \n",
    "    def RMSE(self, R, U, V, W):\n",
    "        self.R_hat = np.dot(V,U.T)\n",
    "\n",
    "        E = (R - (self.imputation_value + self.R_hat))\n",
    "#         W_ = W[Idx] - self.weight\n",
    "        return sqrt(((MFact.Weights==1).astype(np.float) * (E**2)).sum()/np.sum(W[W==1]) )\n",
    "    \n",
    "    '''\n",
    "    OPTIMAZE PER FACTOR\n",
    "    '''\n",
    "    \n",
    "    def compute_item_factor(self, batch):\n",
    "        W, R, V = self.Weights, self.Ratings_matrix, self.Items\n",
    "        lambda_, alfa, r_m = self.lambda_, self.alfa, self.imputation_value\n",
    "        if(self.sparse):\n",
    "            U = sp.csr_matrix(self.Users)\n",
    "        else:\n",
    "            U = self.Users\n",
    "\n",
    "\n",
    "        if(self.opt_method == \"solver\"):\n",
    "            if(self.sparse):\n",
    "                for i in batch:\n",
    "#                     print(i)\n",
    "                    lM = sp.csr_matrix(R[i,:] - r_m).dot(sp.diags(W[i], 0)).dot(U)\n",
    "                    rM = (U.T.dot(sp.diags(W[i], 0))).dot(U) + lambda_ * W[i].sum() * sp.eye(self.no_factors)\n",
    "#                     V[i,:] = lM.dot(sparse_lg.inv(rM)).toarray()[0]\n",
    "                    V[i,:] = sparse_lg.spsolve(rM,lM.T)\n",
    "            elif(not self.sparse):\n",
    "                for i in batch:\n",
    "                    lM = np.dot(np.dot((R[i,:] - r_m),np.diag(W[i,:])),U)\n",
    "                    rM = np.dot(np.dot(U.T,np.diag(W[i,:])),U) + lambda_ * W[i,:].sum() * np.eye(self.no_factors) #np.dot(np.trace(np.diag(W[i,:])),np.eye(self.no_factors))\n",
    "                    V[i,:] = np.dot(lM, inv(rM))\n",
    "#                     V[i,:] = np.linalg.solve(rM,lM)\n",
    "\n",
    "        if(self.opt_method == \"gradient-descent\"):\n",
    "            for i in batch:\n",
    "                for c in range(50):\n",
    "                    V[i] += -alfa * (np.dot((np.dot(V[i], U[Idx[i,:],:].T) - R[i,Idx[i,:]]), U[Idx[i,:],:]) + lambda_ * V[i]) #TODO pri AllRank je to spatne: Brat v uvahu vsechny hodnoceni \n",
    "        return\n",
    "    \n",
    "    def compute_user_factor(self, batch):\n",
    "        W, R, U = self.Weights, self.Ratings_matrix, self.Users\n",
    "        lambda_, alfa, r_m = self.lambda_, self.alfa, self.imputation_value\n",
    "        if(self.sparse):\n",
    "            V = sp.csr_matrix(self.Items)\n",
    "        else:\n",
    "            V = self.Items\n",
    "\n",
    "        if(self.opt_method == \"solver\"):\n",
    "            if(self.sparse):\n",
    "                for u in batch:\n",
    "                    lM = sp.csr_matrix(R[:,u].T - r_m).dot(sp.diags(W[:,u], 0)).dot(V)\n",
    "                    rM = (V.T.dot(sp.diags(W[:,u], 0))).dot(V) + lambda_ * W[:,u].sum() * sp.eye(self.no_factors)\n",
    "#                     U[u,:] = lM.dot(sparse_lg.inv(rM)).toarray()[0]\n",
    "                    U[u,:] = sparse_lg.spsolve(rM,lM.T)\n",
    "        \n",
    "            elif(not self.sparse):\n",
    "                for u in batch:\n",
    "                    lM = np.dot(np.dot(R[:,u].T - r_m, np.diag(W[:,u])), V)\n",
    "                    rM = np.dot(np.dot(V.T,np.diag(W[:,u])), V) + lambda_ * W[:,u].sum() * np.eye(self.no_factors) #np.dot(np.trace(np.diag(W[:,u]))\n",
    "                    U[u,:] = np.dot(lM, inv(rM))\n",
    "#                     U[u,:] = np.linalg.solve(rM,lM)\n",
    "\n",
    "        if(self.opt_method == \"gradient-descent\"):\n",
    "             for u in batch:\n",
    "                for c in range(50):\n",
    "                    U[u] += -alfa * (np.dot((np.dot(U[u], V[Idx[:,u],:].T) - R[Idx[:,u], u].T), V[Idx[:,u],:]) + lambda_* U[u] ) #TODO pri AllRank je to spatne: Brat v uvahu vsechny hodnoceni \n",
    "    \n",
    "        return\n",
    "    '''\n",
    "    OPTIMIZE RMSE\n",
    "    '''\n",
    "    def optimize_rmse(self):\n",
    "        self.init()\n",
    "        self.init_optimizer()\n",
    "        \n",
    "        weighted_errors = []\n",
    "\n",
    "        step_item = int(np.ceil(len(self.Items)/float(self.no_process)))\n",
    "        step_user = int(np.ceil(len(self.Users)/float(self.no_process)))\n",
    "        \n",
    "        item_range = [range(i,min(len(self.Items), i+step_item)) for i in range(0, len(self.Items), step_item)]\n",
    "        user_range = [range(i,min(len(self.Users), i+step_user)) for i in range(0, len(self.Users), step_user)]\n",
    "        print(\"Item range\", item_range)\n",
    "        print(\"User range\", user_range)\n",
    "        \n",
    "        for ii in range(self.no_iterations):\n",
    "            if(not ii % 2):\n",
    "                weighted_errors.append(self.RMSE(self.Ratings_matrix, self.Users, self.Items, self.Weights))\n",
    "                print('{}th iteration is completed'.format(ii))\n",
    "                print(\"RMSE (TRAIN) \", weighted_errors[-1])\n",
    "                start_time = datetime.datetime.now()\n",
    "                atop, rmse = self.ATOP()\n",
    "                print(\"ATOP \", atop, \" RMSE (TEST) \", rmse, \" time \",datetime.datetime.now() - start_time)\n",
    "\n",
    "            #ITEMS                \n",
    "            process = []\n",
    "            for batch in item_range:\n",
    "                p = Process(target = self.compute_item_factor, args = (batch,))\n",
    "                p.daemon = True\n",
    "\n",
    "                process.append(p)\n",
    "                p.start()\n",
    "            \n",
    "            [p.join() for p in process]\n",
    "                \n",
    "            #USERS\n",
    "            process = []\n",
    "            for batch in user_range:\n",
    "                p = Process(target = self.compute_user_factor, args = (batch,))\n",
    "                p.daemon = True\n",
    "\n",
    "                process.append(p)\n",
    "                p.start()\n",
    "            \n",
    "            [p.join() for p in process]\n",
    "\n",
    "        return weighted_errors\n",
    "\n",
    "        \n",
    "    def optimaze(self, no_iterations, loss_function=\"RMSE\", opt_method=\"solver\",  lambda_ = 0.001, alfa=0.00001, \n",
    "                 no_process = 1, random_init = True, weights_mode = \"MF-RMSE\", weight = 0, imputation_value = 0, sparse = False, beta = 0, K = 10):\n",
    "        \n",
    "        self.loss_function = loss_function\n",
    "        self.solve_opt_method = opt_method \n",
    "        self.lambda_ = lambda_\n",
    "        self.alfa = alfa\n",
    "        self.no_process = no_process\n",
    "        self.no_iterations = no_iterations\n",
    "        self.random_init = random_init\n",
    "        self.weights_mode = weights_mode\n",
    "        self.weight = weight\n",
    "        self.imputation_value = imputation_value\n",
    "        self.opt_method = opt_method\n",
    "        self.sparse = sparse\n",
    "        self.beta = beta \n",
    "        self.K = K\n",
    "        \n",
    "        weighted_errors = self.optimize_rmse()\n",
    "        \n",
    "        self.plot_rmse(weighted_errors)\n",
    "        \n",
    "    '''\n",
    "    PLOT AND EXPLORE\n",
    "    '''\n",
    "    def plot_rmse(self, weighted_errors):\n",
    "        plt.plot(np.log(weighted_errors), label=\"weighted error: \"+str(weighted_errors[-1]))\n",
    "        plt.ylabel(\"RMSE log scale\")\n",
    "        plt.xlabel(\"no iterations\")\n",
    "\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def explore(self):\n",
    "        relevant = self.relevant \n",
    "        R = self.Ratings_matrix\n",
    "        no_ratings = np.sum(self.Idx==True)\n",
    "        no_missing = np.sum(self.Idx==False)\n",
    "        no_all = no_ratings + no_missing\n",
    "        \n",
    "        sizes = [no_ratings, no_missing]\n",
    "        labels = [\"ratings\", \"missings\"]\n",
    "        colors = ['yellowgreen', 'lightskyblue']\n",
    "\n",
    "        plt.pie(sizes, labels=labels,\n",
    "                autopct='%1.1f%%', shadow=True, startangle=90, colors= colors)\n",
    "        plt.axis('equal')\n",
    "        plt.show()\n",
    "        print(\"#{} rating, #{} missing\".format(no_ratings, no_missing))\n",
    "        print(\"Estimate offset w(m): \", no_ratings/no_missing)\n",
    "        print(\"Avg of ratings: \", R[self.Idx].mean())\n",
    "        \n",
    "        no_relevant = np.sum(R[self.Idx]>=relevant)\n",
    "        no_irelevant = np.sum(R[self.Idx]<relevant)\n",
    "        labels = [\"relevant\", \"irelevenat\"]\n",
    "\n",
    "        sizes = [no_relevant, no_irelevant]\n",
    "        colors = ['lightskyblue', 'lightcoral']\n",
    "        plt.pie(sizes, labels=labels,\n",
    "                autopct='%1.1f%%', shadow=True, startangle=90, colors= colors)\n",
    "        plt.axis('equal')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"#{} relevant, #{} irelevant\".format(no_relevant, no_irelevant))\n",
    "\n",
    "        items_popularity = np.sort(list(MFact.number_of_obs_relevant_items.values()))[::-1]\n",
    "#         plt.bar(range(len(items_popularity)),items_popularity)\n",
    "        plt.xticks([])\n",
    "        plt.ylabel(\"# of item rating marked as relevant\")\n",
    "        plt.xlabel(\"item\")\n",
    "        plt.plot(items_popularity,'_')\n",
    "        plt.show()\n",
    "        \n",
    "        plt.hist(MFact.Dataset['rating'].values,bins = len(set(MFact.Dataset['rating'])))\n",
    "        plt.xlabel(\"rating\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %lprun -f MFact.rmse_optimalization MFact.rmse_optimalization(0.001, 0.0001, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ifold = 0\n",
    "dataset = ratings[~ratings.userId.isin(user_folds[ifold])]\n",
    "MFact = MatrixFactorization(dataset[:].copy(), 50, relevant = 1., testset_amount = 0.2)\n",
    "for  i in range(MFact.Weights.shape[0]):\n",
    "    if(not np.sum(MFact.Weights[i,:])):\n",
    "        print(np.sum(MFact.Weights[i,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MFact.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Set weight:  0  to missing ratings **\n",
      "Item range [range(0, 529), range(529, 1058), range(1058, 1587), range(1587, 2116), range(2116, 2645), range(2645, 3174), range(3174, 3698)]\n",
      "User range [range(0, 777), range(777, 1554), range(1554, 2331), range(2331, 3108), range(3108, 3885), range(3885, 4662), range(4662, 5436)]\n",
      "0th iteration is completed\n",
      "RMSE (TRAIN)  12.420342791186535\n",
      "ATOP  0.496042724876  RMSE (TEST)  11.646013158934823  time  0:00:01.331495\n",
      "2th iteration is completed\n",
      "RMSE (TRAIN)  0.42101345097950804\n",
      "ATOP  0.846635074581  RMSE (TEST)  0.6072545248814449  time  0:00:01.315831\n",
      "4th iteration is completed\n",
      "RMSE (TRAIN)  0.40462377406112776\n",
      "ATOP  0.859710891103  RMSE (TEST)  0.5758469451535729  time  0:00:01.321525\n",
      "6th iteration is completed\n",
      "RMSE (TRAIN)  0.40025137404505523\n",
      "ATOP  0.862734951392  RMSE (TEST)  0.5697966280444193  time  0:00:01.307996\n",
      "8th iteration is completed\n",
      "RMSE (TRAIN)  0.3983989163428437\n",
      "ATOP  0.86368400697  RMSE (TEST)  0.568091891707482  time  0:00:01.318237\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "MFact.optimaze(10, opt_method=\"solver\",  lambda_ = 0.05, no_process = 7, weights_mode = \"AllRank\", weight = 0, imputation_value = 0 , random_init = True, sparse = True, beta= 0.0, K = 20)\n",
    "datetime.datetime.now() - start_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
